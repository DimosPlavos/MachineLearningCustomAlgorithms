{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize, RandomRotation, RandomHorizontalFlip\n",
    "import torchvision.datasets as datasets\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # MLP Model\n",
    "# class NeuralNet(nn.Module):\n",
    "#     def __init__(self, input_size, hidden_size1, hidden_size2, num_classes):\n",
    "#         super(NeuralNet, self).__init__()\n",
    "#         self.input_size = input_size\n",
    "#         self.l1 = nn.Linear(input_size, hidden_size1)\n",
    "#         self.bn1 = nn.BatchNorm1d(hidden_size1)\n",
    "#         self.relu1 = nn.ReLU()\n",
    "#         self.l2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "#         self.bn2 = nn.BatchNorm1d(hidden_size2)\n",
    "#         self.relu2 = nn.ReLU()\n",
    "#         self.l3 = nn.Linear(hidden_size2, num_classes)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         out = self.l1(x)\n",
    "#         out = self.bn1(out)\n",
    "#         out = self.relu1(out)\n",
    "#         out = self.l2(out)\n",
    "#         out = self.bn2(out)\n",
    "#         out = self.relu2(out)\n",
    "#         out = self.l3(out)\n",
    "#         return out\n",
    "    \n",
    "    \n",
    "# # Training the model\n",
    "# def train_model(model, optimizer, data_loader, loss_module, device, num_epochs=5):\n",
    "#     model.train()\n",
    "#     n_total_steps = len(data_loader)\n",
    "#     for epoch in range(num_epochs):\n",
    "#         for i, (data_inputs, data_labels) in enumerate(data_loader):\n",
    "#             optimizer.zero_grad()\n",
    "#             data_inputs = data_inputs.view(-1, input_size).to(device)\n",
    "#             data_inputs = data_inputs.reshape(-1, input_size).to(device)\n",
    "#             data_labels = data_labels.to(device)\n",
    "            \n",
    "#             # Forward pass\n",
    "#             outputs = model(data_inputs)\n",
    "#             loss = criterion(outputs, data_labels)\n",
    "            \n",
    "#             # Backward and optimize\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "        \n",
    "#             if (i + 1) % 100 == 0:\n",
    "#                 print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
    "\n",
    "#         # Step the learning rate scheduler\n",
    "#         scheduler.step()\n",
    "\n",
    "# # Evaluate the model\n",
    "# def eval_model(model, data_loader, device):\n",
    "#     model.eval()\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "#     with torch.no_grad():\n",
    "#         for data_inputs, data_labels in data_loader:\n",
    "#             data_inputs = data_inputs.view(-1, input_size).to(device)\n",
    "#             data_labels = data_labels.to(device)\n",
    "\n",
    "#             outputs = model(data_inputs)\n",
    "#             _, predicted = torch.max(outputs.data, 1)\n",
    "#             total += data_labels.size(0)\n",
    "#             correct += (predicted == data_labels).sum().item()\n",
    "\n",
    "#     accuracy = correct / total\n",
    "#     print(f'Accuracy of the Classifier on the {len(data_loader.dataset)} test images: {100 * accuracy:.2f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Device configuration\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# # Hyper-parameters \n",
    "# input_size = 32 * 32 * 3  # SVHN images are 32x32 with 3 channels (RGB)\n",
    "# hidden_size1 = 500\n",
    "# hidden_size2 = 500\n",
    "# num_classes = 10\n",
    "# num_epochs = 5  \n",
    "# batch_size = 64\n",
    "# learning_rate = 0.001\n",
    "\n",
    "# # SVHN dataset with data augmentation\n",
    "# transform_train = transforms.Compose([\n",
    "#     transforms.RandomRotation(10),\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "# ])\n",
    "\n",
    "# transform_test = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "# ])\n",
    "\n",
    "# train_dataset = torchvision.datasets.SVHN(root='./data',\n",
    "#                                           split='train',\n",
    "#                                           transform=transform_train,\n",
    "#                                           download=True)\n",
    "\n",
    "# test_dataset = torchvision.datasets.SVHN(root='./data',\n",
    "#                                          split='test',\n",
    "#                                          transform=transform_test,\n",
    "#                                          download=True)\n",
    "\n",
    "# # Data loader\n",
    "# train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "#                                            batch_size=batch_size,\n",
    "#                                            shuffle=True)\n",
    "\n",
    "# test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "#                                           batch_size=batch_size,\n",
    "#                                           shuffle=False)\n",
    "\n",
    "# # Visualize some examples\n",
    "# examples = iter(test_loader)\n",
    "# example_data, example_labels = next(examples)\n",
    "\n",
    "# # Unnormalize and plot the images\n",
    "# def imshow(img):\n",
    "#     img = img / 2 + 0.5  # Unnormalize\n",
    "#     npimg = img.numpy()\n",
    "#     plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "#     plt.show()\n",
    "\n",
    "# imshow(torchvision.utils.make_grid(example_data[:30]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/7], Step [100/1145], Loss: 1.9431\n",
      "Epoch [1/7], Step [200/1145], Loss: 1.7275\n",
      "Epoch [1/7], Step [300/1145], Loss: 1.4634\n",
      "Epoch [1/7], Step [400/1145], Loss: 1.5429\n",
      "Epoch [1/7], Step [500/1145], Loss: 1.4581\n",
      "Epoch [1/7], Step [600/1145], Loss: 1.4355\n",
      "Epoch [1/7], Step [700/1145], Loss: 1.3973\n",
      "Epoch [1/7], Step [800/1145], Loss: 1.3299\n",
      "Epoch [1/7], Step [900/1145], Loss: 1.3288\n",
      "Epoch [1/7], Step [1000/1145], Loss: 1.0706\n",
      "Epoch [1/7], Step [1100/1145], Loss: 1.6263\n",
      "Epoch [2/7], Step [100/1145], Loss: 0.9739\n",
      "Epoch [2/7], Step [200/1145], Loss: 1.1762\n",
      "Epoch [2/7], Step [300/1145], Loss: 1.0835\n",
      "Epoch [2/7], Step [400/1145], Loss: 1.2016\n",
      "Epoch [2/7], Step [500/1145], Loss: 1.1608\n",
      "Epoch [2/7], Step [600/1145], Loss: 0.9514\n",
      "Epoch [2/7], Step [700/1145], Loss: 1.1922\n",
      "Epoch [2/7], Step [800/1145], Loss: 0.9299\n",
      "Epoch [2/7], Step [900/1145], Loss: 1.2110\n",
      "Epoch [2/7], Step [1000/1145], Loss: 1.0887\n",
      "Epoch [2/7], Step [1100/1145], Loss: 1.0468\n",
      "Epoch [3/7], Step [100/1145], Loss: 1.1033\n",
      "Epoch [3/7], Step [200/1145], Loss: 1.1185\n",
      "Epoch [3/7], Step [300/1145], Loss: 0.8849\n",
      "Epoch [3/7], Step [400/1145], Loss: 1.0397\n",
      "Epoch [3/7], Step [500/1145], Loss: 0.9986\n",
      "Epoch [3/7], Step [600/1145], Loss: 0.9900\n",
      "Epoch [3/7], Step [700/1145], Loss: 0.9396\n",
      "Epoch [3/7], Step [800/1145], Loss: 0.9125\n",
      "Epoch [3/7], Step [900/1145], Loss: 0.9834\n",
      "Epoch [3/7], Step [1000/1145], Loss: 0.8458\n",
      "Epoch [3/7], Step [1100/1145], Loss: 1.0575\n",
      "Epoch [4/7], Step [100/1145], Loss: 0.7233\n",
      "Epoch [4/7], Step [200/1145], Loss: 0.6781\n",
      "Epoch [4/7], Step [300/1145], Loss: 0.8010\n",
      "Epoch [4/7], Step [400/1145], Loss: 0.7946\n",
      "Epoch [4/7], Step [500/1145], Loss: 0.7445\n",
      "Epoch [4/7], Step [600/1145], Loss: 1.0387\n",
      "Epoch [4/7], Step [700/1145], Loss: 0.8885\n",
      "Epoch [4/7], Step [800/1145], Loss: 0.7107\n",
      "Epoch [4/7], Step [900/1145], Loss: 0.7036\n",
      "Epoch [4/7], Step [1000/1145], Loss: 0.7630\n",
      "Epoch [4/7], Step [1100/1145], Loss: 0.8639\n",
      "Epoch [5/7], Step [100/1145], Loss: 0.9041\n",
      "Epoch [5/7], Step [200/1145], Loss: 0.8613\n",
      "Epoch [5/7], Step [300/1145], Loss: 0.7624\n",
      "Epoch [5/7], Step [400/1145], Loss: 0.6677\n",
      "Epoch [5/7], Step [500/1145], Loss: 0.8692\n",
      "Epoch [5/7], Step [600/1145], Loss: 0.7527\n",
      "Epoch [5/7], Step [700/1145], Loss: 0.5862\n",
      "Epoch [5/7], Step [800/1145], Loss: 0.9884\n",
      "Epoch [5/7], Step [900/1145], Loss: 0.8977\n",
      "Epoch [5/7], Step [1000/1145], Loss: 0.9216\n",
      "Epoch [5/7], Step [1100/1145], Loss: 0.7196\n",
      "Epoch [6/7], Step [100/1145], Loss: 0.6837\n",
      "Epoch [6/7], Step [200/1145], Loss: 0.6217\n",
      "Epoch [6/7], Step [300/1145], Loss: 0.6284\n",
      "Epoch [6/7], Step [400/1145], Loss: 0.7490\n",
      "Epoch [6/7], Step [500/1145], Loss: 0.6730\n",
      "Epoch [6/7], Step [600/1145], Loss: 0.8450\n",
      "Epoch [6/7], Step [700/1145], Loss: 0.7599\n",
      "Epoch [6/7], Step [800/1145], Loss: 0.5964\n",
      "Epoch [6/7], Step [900/1145], Loss: 0.8478\n",
      "Epoch [6/7], Step [1000/1145], Loss: 0.4463\n",
      "Epoch [6/7], Step [1100/1145], Loss: 0.8816\n",
      "Epoch [7/7], Step [100/1145], Loss: 0.7490\n",
      "Epoch [7/7], Step [200/1145], Loss: 0.5978\n",
      "Epoch [7/7], Step [300/1145], Loss: 0.6984\n",
      "Epoch [7/7], Step [400/1145], Loss: 0.6166\n",
      "Epoch [7/7], Step [500/1145], Loss: 0.8759\n",
      "Epoch [7/7], Step [600/1145], Loss: 0.5141\n",
      "Epoch [7/7], Step [700/1145], Loss: 0.9092\n",
      "Epoch [7/7], Step [800/1145], Loss: 0.6445\n",
      "Epoch [7/7], Step [900/1145], Loss: 0.5852\n",
      "Epoch [7/7], Step [1000/1145], Loss: 0.6029\n",
      "Epoch [7/7], Step [1100/1145], Loss: 0.5013\n",
      "Accuracy of the Classifier on the 26032 test images: 77.88 %\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model, Weight initialization function\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_normal_(m.weight.data)\n",
    "\n",
    "# # model = NeuralNet(input_size, hidden_size1, hidden_size2, num_classes).to(device)\n",
    "# model = NeuralNet(input_size, hidden_size1,hidden_size2, num_classes).to(device)\n",
    "# model.apply(weights_init)\n",
    "\n",
    "# Add L1 regularization to linear layers\n",
    "l1_lambda = 0.001  # Adjust this regularization strength\n",
    "model = NeuralNet(input_size, hidden_size1, hidden_size2, num_classes).to(device)\n",
    "model.apply(weights_init)\n",
    "\n",
    "# Add L1 regularization to linear layers\n",
    "for name, param in model.named_parameters():\n",
    "    if 'weight' in name:\n",
    "        new_name = name.replace('.', '_') + '_l1'  # Replace dot with underscore\n",
    "        param.requires_grad = True\n",
    "        model.register_parameter(new_name, nn.Parameter(torch.zeros_like(param), requires_grad=False))\n",
    "        \n",
    "# loss function, and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "# Train the model\n",
    "train_model(model, optimizer, train_loader, criterion, device, num_epochs=7)\n",
    "\n",
    "# Evaluate the model\n",
    "eval_model(model, test_loader, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
