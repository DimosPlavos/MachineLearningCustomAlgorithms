{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MulticlassLogisticRegression():\n",
    "    def __init__(self, learning_rate, num_iterations):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_iterations = num_iterations\n",
    "        self.weights = None\n",
    "\n",
    "    def softmax(self, t):\n",
    "        exp_t = np.exp(t - np.max(t, axis=0, keepdims=True))\n",
    "        return exp_t / np.sum(exp_t, axis=0, keepdims=True)\n",
    "\n",
    "    def fit(self, x_train, y_train):\n",
    "        \"\"\"\n",
    "        Fit the multiclass logistic regression model.\n",
    "\n",
    "        Parameters:\n",
    "            x_train: Input features\n",
    "            y_train: Target labels\n",
    "        \"\"\"\n",
    "        # Split the data into training and validation sets\n",
    "        x_train, x_valuation, y_train, y_valuation = train_test_split(x_train, y_train, test_size=0.1)\n",
    "\n",
    "        num_of_classes = len(np.unique(y_train))\n",
    "        num_of_features = x_train.shape[1]\n",
    "        num_of_examples = x_train.shape[0]\n",
    "\n",
    "        # One-hot encode the target labels\n",
    "        encoder = OneHotEncoder(sparse_output=False)\n",
    "        y_train_one_hot = encoder.fit_transform(y_train.reshape(-1, 1))\n",
    "\n",
    "        # Concatenate a column of ones to the left side of the entire array (bias term)\n",
    "        x_train = np.c_[np.ones(num_of_examples), x_train]\n",
    "\n",
    "        # Step 1: start with random weights\n",
    "        self.weights = np.random.rand(num_of_features + 1, num_of_classes)\n",
    "\n",
    "        iteration = 1\n",
    "        unchanged_epochs = 0\n",
    "        best_s = 0\n",
    "\n",
    "        while iteration <= self.num_iterations:\n",
    "            # Shuffle the data\n",
    "            permutation_index = np.random.permutation(num_of_examples)\n",
    "            shuffled_y_train = y_train_one_hot[permutation_index]\n",
    "            shuffled_x_train = x_train[permutation_index]\n",
    "\n",
    "            # Iterate through each example\n",
    "            for i in range(num_of_examples):\n",
    "                # Step 2: calculate probabilities using softmax\n",
    "                t = np.dot(shuffled_x_train[i], self.weights)\n",
    "                probabilities = self.softmax(t)\n",
    "\n",
    "                # Step 3: calculate the gradient\n",
    "                gradient = -np.outer(shuffled_x_train[i], (shuffled_y_train[i] - probabilities))\n",
    "\n",
    "                # Step 4: update weights using the outer product\n",
    "                self.weights = self.weights - self.learning_rate * gradient\n",
    "\n",
    "            # Step 5: checking accuracy on the validation set\n",
    "            y_pred = np.argmax(self.predict_proba(x_valuation), axis=1)\n",
    "            s = accuracy_score(y_valuation, y_pred)             \n",
    "            # s = accuracy_score(y_valuation, self.predict(x_valuation))\n",
    "\n",
    "            if s > best_s:\n",
    "                best_s = s\n",
    "                best_weights = self.weights\n",
    "                unchanged_epochs = 0\n",
    "            else:\n",
    "                iteration += 1\n",
    "                unchanged_epochs += 1\n",
    "\n",
    "            if unchanged_epochs == 31:\n",
    "                self.weights = best_weights\n",
    "                break\n",
    "\n",
    "        return x_train, y_train\n",
    "\n",
    "\n",
    "    def predict(self, x_test):\n",
    "        return np.argmax(self.predict_proba(x_test), axis=1)\n",
    "    \n",
    "    def predict_proba(self, x_test):\n",
    "        num_of_examples = x_test.shape[0]\n",
    "        x_test = np.c_[np.ones(num_of_examples), x_test]\n",
    "        y_pred = list()\n",
    "        \n",
    "        for example in x_test:\n",
    "            t = np.dot(example, self.weights)\n",
    "            y_pred.append(self.softmax(t))\n",
    "            \n",
    "        return np.array(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dplavos/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target variable y:\n",
      "[1 1 1 ... 4 4 4]\n",
      "First few rows of the dataset:\n",
      "        Age    Height    Weight      FCVC       NCP      CH2O       FAF  \\\n",
      "0 -0.522001 -0.875382 -0.862354 -0.784833  0.404057 -0.013070 -1.187758   \n",
      "1 -0.522001 -1.947138 -1.167800  1.088084  0.404057  1.618375  2.339196   \n",
      "2 -0.206840  1.053779 -0.366003 -0.784833  0.404057 -0.013070  1.163545   \n",
      "3  0.423481  1.053779  0.015805  1.088084  0.404057 -0.013070  1.163545   \n",
      "4 -0.364420  0.839428  0.122711 -0.784833 -2.166509 -0.013070 -1.187758   \n",
      "\n",
      "        TUE  \n",
      "0  0.561864  \n",
      "1 -1.080369  \n",
      "2  0.561864  \n",
      "3 -1.080369  \n",
      "4 -1.080369  \n",
      "Accuracy on the custom model test set: 0.8739933680720038\n",
      "Classification report for Custom Logistic Regression at Testing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92       272\n",
      "           1       0.93      0.73      0.82       287\n",
      "           2       0.95      0.93      0.94       351\n",
      "           3       0.95      0.97      0.96       297\n",
      "           4       0.96      1.00      0.98       324\n",
      "           5       0.69      0.76      0.72       290\n",
      "           6       0.77      0.71      0.74       290\n",
      "\n",
      "    accuracy                           0.87      2111\n",
      "   macro avg       0.87      0.87      0.87      2111\n",
      "weighted avg       0.88      0.87      0.87      2111\n",
      "\n",
      "Accuracy on scikit-learn's model test set: 0.9076267171956419\n",
      "Classification report for Logistic Regression from scikit-learn at Testing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95       272\n",
      "           1       0.95      0.79      0.86       287\n",
      "           2       0.96      0.91      0.93       351\n",
      "           3       0.93      0.96      0.95       297\n",
      "           4       0.96      1.00      0.98       324\n",
      "           5       0.78      0.87      0.83       290\n",
      "           6       0.87      0.81      0.84       290\n",
      "\n",
      "    accuracy                           0.91      2111\n",
      "   macro avg       0.91      0.91      0.91      2111\n",
      "weighted avg       0.91      0.91      0.91      2111\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fetch dataset\n",
    "estimation_of_obesity_levels_based_on_eating_habits_and_physical_condition = fetch_ucirepo(id=544)\n",
    "\n",
    "# Data (as pandas dataframes)\n",
    "X = estimation_of_obesity_levels_based_on_eating_habits_and_physical_condition.data.features\n",
    "y = estimation_of_obesity_levels_based_on_eating_habits_and_physical_condition.data.targets\n",
    "\n",
    "# Drop categorical columns\n",
    "string_columns = ['MTRANS', 'Gender', 'family_history_with_overweight', 'FAVC', 'CALC', 'SCC', 'SMOKE', 'CAEC']\n",
    "X = X.drop(string_columns, axis=1)\n",
    "\n",
    "# Convert the target variable to numerical format\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y).ravel()\n",
    "\n",
    "# Print the values of the target variable y\n",
    "print(\"Target variable y:\")\n",
    "print(y)\n",
    "\n",
    "# Standardization\n",
    "mu = X.mean()\n",
    "stdu = X.std()\n",
    "X = (X - mu) / stdu\n",
    "\n",
    "# Print the first few rows of the dataset to inspect features and values\n",
    "print(\"First few rows of the dataset:\")\n",
    "print(X.head())\n",
    "# Convert pandas dataframe to numpy array\n",
    "X = X.to_numpy()\n",
    "# y = y.to_numpy()\n",
    "\n",
    "np.random.seed(42)\n",
    "# Instantiate and train the logistic regression model\n",
    "lr = MulticlassLogisticRegression(learning_rate=0.00215, num_iterations=170)\n",
    "x_train, y_train = lr.fit(X, y)\n",
    "# Test the custom model on a separate dataset\n",
    "\n",
    "y_test_pred_custom = lr.predict(X)\n",
    "\n",
    "# Evaluate the accuracy on the test set for the custom model\n",
    "accuracy_custom = accuracy_score(y, y_test_pred_custom)\n",
    "print(f\"Accuracy on the custom model test set: {accuracy_custom}\")\n",
    "\n",
    "# Print classification report for the custom model\n",
    "print(\"Classification report for Custom Logistic Regression at Testing\")\n",
    "print(classification_report(y, y_test_pred_custom))\n",
    "\n",
    "# Remove the bias term from X before using scikit-learn's model\n",
    "X_no_bias = X[:, 1:]\n",
    "\n",
    "# Instantiate and train scikit-learn's logistic regression model\n",
    "log = LogisticRegression()\n",
    "log.fit(X_no_bias, y)\n",
    "\n",
    "# Evaluate the accuracy of scikit-learn's model on the test set\n",
    "y_test_pred_sklearn = log.predict(X_no_bias)\n",
    "accuracy_sklearn = accuracy_score(y, y_test_pred_sklearn)\n",
    "print(f\"Accuracy on scikit-learn's model test set: {accuracy_sklearn}\")\n",
    "\n",
    "# Print classification report for scikit-learn's Logistic Regression\n",
    "print(\"Classification report for Logistic Regression from scikit-learn at Testing\")\n",
    "print(classification_report(y, y_test_pred_sklearn))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
